{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5825c041-6e6e-451a-ab09-67b6b256376a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb5e610-4c9c-4748-a4c2-f7f10c679c4d",
   "metadata": {},
   "source": [
    "### Yolo Large model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fd1871a-5f67-403c-8762-997dce951923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO('yolo11l.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68ba07f7-14b7-4389-b82a-e24a1feb037c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n"
     ]
    }
   ],
   "source": [
    "class_list = model.names \n",
    "#class_list\n",
    "print(class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fedb79f2-e644-4ac3-9983-af1b4a7195cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Vehicle crossed! Total count: 1\n",
      " Vehicle crossed! Total count: 2\n",
      " Vehicle crossed! Total count: 3\n",
      " Vehicle crossed! Total count: 4\n",
      " Vehicle crossed! Total count: 5\n",
      " Vehicle crossed! Total count: 6\n",
      " Vehicle crossed! Total count: 7\n",
      " Vehicle crossed! Total count: 8\n",
      " Vehicle crossed! Total count: 9\n",
      " Vehicle crossed! Total count: 10\n",
      " Vehicle crossed! Total count: 11\n",
      " Vehicle crossed! Total count: 12\n",
      " Vehicle crossed! Total count: 13\n",
      " Vehicle crossed! Total count: 14\n",
      " Vehicle crossed! Total count: 15\n",
      " Vehicle crossed! Total count: 16\n",
      " Vehicle crossed! Total count: 17\n",
      " Vehicle crossed! Total count: 18\n",
      " Vehicle crossed! Total count: 19\n",
      " Vehicle crossed! Total count: 20\n",
      "\n",
      "âš ï¸ 20 vehicles crossed! Traffic light changing sequence begins...\n",
      "ðŸŸ¡ Yellow Light - Prepare to Stop...\n",
      "ðŸ”´ Red Light - Stop for 5 seconds...\n",
      "\n",
      "ðŸŸ¢ Green Light - Resuming Traffic!\n",
      "\n",
      " Vehicle crossed! Total count: 1\n",
      " Vehicle crossed! Total count: 2\n",
      " Vehicle crossed! Total count: 3\n",
      " Vehicle crossed! Total count: 4\n",
      " Vehicle crossed! Total count: 5\n",
      " Vehicle crossed! Total count: 6\n",
      " Vehicle crossed! Total count: 7\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "# âœ… Load YOLO model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = YOLO('yolo11m.pt').to(device)\n",
    "\n",
    "# âœ… Open video file\n",
    "cap = cv2.VideoCapture('4.mp4')\n",
    "\n",
    "# âœ… Get frame height to position red line at center\n",
    "ret, test_frame = cap.read()\n",
    "if not ret:\n",
    "    print(\"Error: Cannot read video file.\")\n",
    "    cap.release()\n",
    "    exit()\n",
    "\n",
    "frame_height = test_frame.shape[0]\n",
    "line_y_red = frame_height // 2  # red line in center\n",
    "\n",
    "# âœ… Vehicle classes (car, motorcycle, bus, truck)\n",
    "vehicle_classes = [2, 3, 5, 7]\n",
    "\n",
    "# âœ… Counters and tracking\n",
    "class_counts = defaultdict(int)\n",
    "crossed_ids = set()\n",
    "frame_id = 0\n",
    "frame_skip = 2\n",
    "total_count = 0  # total vehicles counted\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_id += 1\n",
    "    if frame_id % frame_skip != 0:\n",
    "        continue\n",
    "\n",
    "    # Resize for better performance\n",
    "    frame = cv2.resize(frame, (640, 360))\n",
    "    line_y_red = frame.shape[0] // 2  # recalc for resized frame\n",
    "\n",
    "    # âœ… Run YOLO tracking\n",
    "    results = model.track(frame, persist=True, classes=vehicle_classes, conf=0.6, verbose=False)\n",
    "\n",
    "    # âœ… Draw red line\n",
    "    cv2.line(frame, (50, line_y_red), (590, line_y_red), (0, 0, 255), 3)\n",
    "    cv2.putText(frame, \"Counting Line\", (50, line_y_red - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "    # âœ… Process detections\n",
    "    if results and results[0].boxes.id is not None:\n",
    "        boxes = results[0].boxes.xyxy.cpu()\n",
    "        class_indices = results[0].boxes.cls.int().cpu().tolist()\n",
    "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "\n",
    "        for box, cls_idx, tid in zip(boxes, class_indices, track_ids):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            cx, cy = (x1 + x2)//2, (y1 + y2)//2\n",
    "            class_name = model.names[cls_idx]\n",
    "\n",
    "            # Draw detection info\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.circle(frame, (cx, cy), 3, (0, 0, 255), -1)\n",
    "            cv2.putText(frame, f\"{class_name} ID:{tid}\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n",
    "\n",
    "            # âœ… Count only once when crossing the line\n",
    "            if cy > line_y_red and tid not in crossed_ids:\n",
    "                crossed_ids.add(tid)\n",
    "                class_counts[class_name] += 1\n",
    "                total_count += 1\n",
    "                print(f\" Vehicle crossed! Total count: {total_count}\")\n",
    "\n",
    "                # âœ… Simulate traffic light event\n",
    "                if total_count == 20:\n",
    "                    print(\"\\nâš ï¸ 20 vehicles crossed! Traffic light changing sequence begins...\")\n",
    "                    print(\"ðŸŸ¡ Yellow Light - Prepare to Stop...\")\n",
    "                    cv2.putText(frame, \"Yellow Light - Prepare to Stop\", (100, 50),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 3)\n",
    "                    cv2.imshow(\"YOLO Vehicle Detection & Counting\", frame)\n",
    "                    cv2.waitKey(2000)\n",
    "\n",
    "                    print(\"ðŸ”´ Red Light - Stop for 5 seconds...\\n\")\n",
    "                    cv2.putText(frame, \"Red Light - STOP\", (180, 50),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 3)\n",
    "                    cv2.imshow(\"YOLO Vehicle Detection & Counting\", frame)\n",
    "                    cv2.waitKey(5000)\n",
    "\n",
    "                    print(\"ðŸŸ¢ Green Light - Resuming Traffic!\\n\")\n",
    "                    total_count = 0  # Reset after light cycle\n",
    "                    crossed_ids.clear()  # reset IDs after cycle\n",
    "\n",
    "    # âœ… Display count info\n",
    "    y = 30\n",
    "    cv2.putText(frame, \"Vehicle Counts:\", (20, y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "    y += 25\n",
    "    for cls, count in class_counts.items():\n",
    "        cv2.putText(frame, f\"{cls}: {count}\", (20, y),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        y += 25\n",
    "\n",
    "    cv2.imshow(\"YOLO Vehicle Detection & Counting\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c20bcdcd-dbb2-4116-98af-91d045dcb45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "# âœ… Load YOLO model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = YOLO('yolo11m.pt').to(device)\n",
    "\n",
    "# âœ… Open video file\n",
    "cap = cv2.VideoCapture('4.mp4')\n",
    "\n",
    "# Line position (a bit higher)\n",
    "line_y_red = 260  \n",
    "\n",
    "# âœ… Vehicle classes\n",
    "vehicle_classes = [2, 3, 5, 7]  # car, motorcycle, bus, truck\n",
    "\n",
    "# âœ… Counters and tracking memory\n",
    "class_counts = defaultdict(int)\n",
    "crossed_ids = set()  # remember which IDs have crossed\n",
    "\n",
    "# âœ… Frame skip to improve speed\n",
    "frame_id = 0\n",
    "frame_skip = 2  \n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_id += 1\n",
    "    if frame_id % frame_skip != 0:\n",
    "        continue\n",
    "\n",
    "    frame = cv2.resize(frame, (640, 360))\n",
    "\n",
    "    # âœ… Run YOLO tracking (not just detect)\n",
    "    results = model.track(frame, persist=True, classes=vehicle_classes, conf=0.6, verbose=False)\n",
    "\n",
    "    # âœ… Draw counting line\n",
    "    cv2.line(frame, (100, line_y_red), (540, line_y_red), (0, 0, 255), 3)\n",
    "    cv2.putText(frame, \"Counting Line\", (100, line_y_red - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "    # âœ… Process tracked detections\n",
    "    if results and results[0].boxes.id is not None:\n",
    "        boxes = results[0].boxes.xyxy.cpu()\n",
    "        class_indices = results[0].boxes.cls.int().cpu().tolist()\n",
    "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "\n",
    "        for box, cls_idx, tid in zip(boxes, class_indices, track_ids):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            cx, cy = (x1 + x2)//2, (y1 + y2)//2\n",
    "            class_name = model.names[cls_idx]\n",
    "\n",
    "            # Draw tracking box & label\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.circle(frame, (cx, cy), 3, (0, 0, 255), -1)\n",
    "            cv2.putText(frame, f\"ID:{tid} {class_name}\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n",
    "\n",
    "            # âœ… Count vehicle only ONCE when it crosses the line\n",
    "            if cy > line_y_red and tid not in crossed_ids:\n",
    "                crossed_ids.add(tid)\n",
    "                class_counts[class_name] += 1\n",
    "\n",
    "    # âœ… Display count info\n",
    "    y = 30\n",
    "    cv2.putText(frame, \"Vehicle Counts:\", (20, y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "    y += 25\n",
    "    for cls, count in class_counts.items():\n",
    "        cv2.putText(frame, f\"{cls}: {count}\", (20, y),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        y += 25\n",
    "\n",
    "    cv2.imshow(\"YOLO Vehicle Detection & Counting\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a125d9f-ab95-467f-8257-3ebd3572e11d",
   "metadata": {},
   "source": [
    "### Faster Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8676ca61-e090-418e-8e97-cc41e7060044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the video file\n",
    "cap = cv2.VideoCapture('4.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a049d501-4764-4583-be30-531573410c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 10 cars, 3 motorcycles, 3 buss, 1 truck, 47.6ms\n",
      "Speed: 3.0ms preprocess, 47.6ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 3 motorcycles, 3 buss, 1 truck, 127.2ms\n",
      "Speed: 4.2ms preprocess, 127.2ms inference, 21.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 3 motorcycles, 3 buss, 1 truck, 312.5ms\n",
      "Speed: 3.8ms preprocess, 312.5ms inference, 42.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 3 motorcycles, 3 buss, 1 truck, 47.3ms\n",
      "Speed: 1.6ms preprocess, 47.3ms inference, 23.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 4 motorcycles, 3 buss, 1 truck, 47.0ms\n",
      "Speed: 2.1ms preprocess, 47.0ms inference, 24.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 4 motorcycles, 3 buss, 1 truck, 48.0ms\n",
      "Speed: 3.0ms preprocess, 48.0ms inference, 21.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 4 motorcycles, 3 buss, 2 trucks, 166.6ms\n",
      "Speed: 3.3ms preprocess, 166.6ms inference, 20.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 4 motorcycles, 3 buss, 2 trucks, 47.2ms\n",
      "Speed: 2.1ms preprocess, 47.2ms inference, 31.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 3 motorcycles, 3 buss, 2 trucks, 47.2ms\n",
      "Speed: 3.0ms preprocess, 47.2ms inference, 20.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO('yolo11l.pt')\n",
    "\n",
    "class_list = model.names \n",
    "#class_list\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture('4.mp4')\n",
    "\n",
    "line_y_red = 430  # Red line position\n",
    "\n",
    "# Dictionary to store object counts by class\n",
    "class_counts = defaultdict(int)\n",
    "\n",
    "# Dictionary to keep track of object IDs that have crossed the line\n",
    "crossed_ids = set()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Run YOLO tracking on the frame\n",
    "    results = model.track(frame, persist=True, classes = [1,2,3,5,6,7]) \n",
    "    #print(results)\n",
    "\n",
    "    # Ensure results are not empty\n",
    "    if results[0].boxes.data is not None:\n",
    "        # Get the detected boxes, their class indices, and track IDs\n",
    "        boxes = results[0].boxes.xyxy.cpu()\n",
    "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "        class_indices = results[0].boxes.cls.int().cpu().tolist()\n",
    "        confidences = results[0].boxes.conf.cpu()\n",
    "\n",
    "        cv2.line(frame, (690, line_y_red), (1130, line_y_red), (0, 0, 255), 3)\n",
    "        #cv2.putText(frame, 'Red Line', (690, line_y_red - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        # Loop through each detected object\n",
    "        for box, track_id, class_idx, conf in zip(boxes, track_ids, class_indices, confidences):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            cx = (x1 + x2) // 2  # Calculate the center point\n",
    "            cy = (y1 + y2) // 2            \n",
    "\n",
    "            class_name = class_list[class_idx]\n",
    "\n",
    "            cv2.circle(frame, (cx, cy), 4, (0, 0, 255), -1)\n",
    "            \n",
    "            cv2.putText(frame, f\"ID: {track_id} {class_name}\", (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2) \n",
    "\n",
    "\n",
    "            # Check if the object has crossed the red line\n",
    "            if cy > line_y_red and track_id not in crossed_ids:\n",
    "                # Mark the object as crossed\n",
    "                crossed_ids.add(track_id)\n",
    "                class_counts[class_name] += 1\n",
    "\n",
    "\n",
    "        # Display the counts on the frame\n",
    "        y_offset = 30\n",
    "        for class_name, count in class_counts.items():\n",
    "            cv2.putText(frame, f\"{class_name}: {count}\", (50, y_offset),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "            y_offset += 30\n",
    "\n",
    "    \n",
    "    \n",
    "    # Show the frame\n",
    "    cv2.imshow(\"YOLO Object Tracking & Counting\", frame)    \n",
    "    \n",
    "    # Exit loop if 'q' key is pressed\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775ce6e8-7b83-4306-9ab6-bfbf00ae2ba1",
   "metadata": {},
   "source": [
    "### Yolo medium model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cc857f6-a773-4abe-a49d-c69d67f9f5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 7 cars, 1 truck, 38.8ms\n",
      "Speed: 2.6ms preprocess, 38.8ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 truck, 117.5ms\n",
      "Speed: 2.9ms preprocess, 117.5ms inference, 18.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 truck, 269.2ms\n",
      "Speed: 2.4ms preprocess, 269.2ms inference, 21.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 truck, 205.2ms\n",
      "Speed: 2.7ms preprocess, 205.2ms inference, 18.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 truck, 36.9ms\n",
      "Speed: 3.0ms preprocess, 36.9ms inference, 17.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 truck, 36.1ms\n",
      "Speed: 1.4ms preprocess, 36.1ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 truck, 36.4ms\n",
      "Speed: 1.7ms preprocess, 36.4ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 truck, 36.1ms\n",
      "Speed: 2.0ms preprocess, 36.1ms inference, 9.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 truck, 36.1ms\n",
      "Speed: 1.9ms preprocess, 36.1ms inference, 18.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 truck, 36.2ms\n",
      "Speed: 1.2ms preprocess, 36.2ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 bus, 37.2ms\n",
      "Speed: 1.7ms preprocess, 37.2ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 truck, 36.4ms\n",
      "Speed: 1.8ms preprocess, 36.4ms inference, 18.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 truck, 36.3ms\n",
      "Speed: 1.7ms preprocess, 36.3ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 36.4ms\n",
      "Speed: 2.1ms preprocess, 36.4ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 36.3ms\n",
      "Speed: 1.3ms preprocess, 36.3ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 36.7ms\n",
      "Speed: 2.8ms preprocess, 36.7ms inference, 22.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 36.1ms\n",
      "Speed: 1.7ms preprocess, 36.1ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 36.6ms\n",
      "Speed: 1.9ms preprocess, 36.6ms inference, 20.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 36.5ms\n",
      "Speed: 2.5ms preprocess, 36.5ms inference, 19.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 36.1ms\n",
      "Speed: 1.7ms preprocess, 36.1ms inference, 22.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 2 trucks, 166.0ms\n",
      "Speed: 1.6ms preprocess, 166.0ms inference, 30.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 288.6ms\n",
      "Speed: 1.9ms preprocess, 288.6ms inference, 10.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 truck, 36.1ms\n",
      "Speed: 2.0ms preprocess, 36.1ms inference, 20.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 truck, 36.4ms\n",
      "Speed: 2.1ms preprocess, 36.4ms inference, 21.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 truck, 174.5ms\n",
      "Speed: 2.5ms preprocess, 174.5ms inference, 21.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 truck, 258.8ms\n",
      "Speed: 10.1ms preprocess, 258.8ms inference, 24.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 bus, 1 truck, 36.3ms\n",
      "Speed: 1.4ms preprocess, 36.3ms inference, 18.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 36.8ms\n",
      "Speed: 1.9ms preprocess, 36.8ms inference, 18.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 36.4ms\n",
      "Speed: 1.6ms preprocess, 36.4ms inference, 17.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 truck, 36.4ms\n",
      "Speed: 2.7ms preprocess, 36.4ms inference, 18.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 36.9ms\n",
      "Speed: 1.4ms preprocess, 36.9ms inference, 25.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 36.2ms\n",
      "Speed: 2.4ms preprocess, 36.2ms inference, 19.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 truck, 36.3ms\n",
      "Speed: 2.6ms preprocess, 36.3ms inference, 18.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 bus, 1 truck, 36.4ms\n",
      "Speed: 2.0ms preprocess, 36.4ms inference, 18.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 36.1ms\n",
      "Speed: 1.2ms preprocess, 36.1ms inference, 18.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 36.6ms\n",
      "Speed: 1.9ms preprocess, 36.6ms inference, 20.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 36.6ms\n",
      "Speed: 2.2ms preprocess, 36.6ms inference, 21.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 36.5ms\n",
      "Speed: 2.2ms preprocess, 36.5ms inference, 18.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 36.5ms\n",
      "Speed: 2.8ms preprocess, 36.5ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 36.5ms\n",
      "Speed: 2.1ms preprocess, 36.5ms inference, 15.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 36.4ms\n",
      "Speed: 2.8ms preprocess, 36.4ms inference, 14.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 125.2ms\n",
      "Speed: 2.8ms preprocess, 125.2ms inference, 23.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 224.9ms\n",
      "Speed: 2.4ms preprocess, 224.9ms inference, 17.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 38.8ms\n",
      "Speed: 1.7ms preprocess, 38.8ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 1 truck, 36.2ms\n",
      "Speed: 1.0ms preprocess, 36.2ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 36.4ms\n",
      "Speed: 1.6ms preprocess, 36.4ms inference, 15.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 58.3ms\n",
      "Speed: 2.0ms preprocess, 58.3ms inference, 20.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 1 truck, 160.2ms\n",
      "Speed: 1.8ms preprocess, 160.2ms inference, 29.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 2 buss, 267.8ms\n",
      "Speed: 3.0ms preprocess, 267.8ms inference, 17.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 bus, 1 truck, 36.1ms\n",
      "Speed: 2.4ms preprocess, 36.1ms inference, 14.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 truck, 36.3ms\n",
      "Speed: 1.4ms preprocess, 36.3ms inference, 19.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 2 buss, 1 truck, 36.3ms\n",
      "Speed: 2.6ms preprocess, 36.3ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 bus, 1 truck, 38.7ms\n",
      "Speed: 1.8ms preprocess, 38.7ms inference, 19.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 3 trucks, 163.5ms\n",
      "Speed: 1.4ms preprocess, 163.5ms inference, 21.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 262.5ms\n",
      "Speed: 2.5ms preprocess, 262.5ms inference, 24.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 36.5ms\n",
      "Speed: 1.8ms preprocess, 36.5ms inference, 13.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 1 truck, 36.2ms\n",
      "Speed: 1.1ms preprocess, 36.2ms inference, 12.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 36.4ms\n",
      "Speed: 1.5ms preprocess, 36.4ms inference, 21.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 bus, 36.1ms\n",
      "Speed: 2.1ms preprocess, 36.1ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 cars, 1 truck, 36.8ms\n",
      "Speed: 2.2ms preprocess, 36.8ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 bus, 1 truck, 36.0ms\n",
      "Speed: 1.4ms preprocess, 36.0ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 bus, 1 truck, 36.1ms\n",
      "Speed: 1.2ms preprocess, 36.1ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 train, 1 truck, 36.5ms\n",
      "Speed: 2.5ms preprocess, 36.5ms inference, 12.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 2 trucks, 36.2ms\n",
      "Speed: 1.0ms preprocess, 36.2ms inference, 12.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 bus, 2 trucks, 42.7ms\n",
      "Speed: 1.2ms preprocess, 42.7ms inference, 15.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 bus, 2 trucks, 143.0ms\n",
      "Speed: 2.1ms preprocess, 143.0ms inference, 12.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 bus, 2 trucks, 131.7ms\n",
      "Speed: 1.7ms preprocess, 131.7ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 bus, 2 trucks, 36.6ms\n",
      "Speed: 1.1ms preprocess, 36.6ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 bus, 2 trucks, 36.1ms\n",
      "Speed: 1.5ms preprocess, 36.1ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 bus, 3 trucks, 36.2ms\n",
      "Speed: 1.3ms preprocess, 36.2ms inference, 9.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 bus, 3 trucks, 36.5ms\n",
      "Speed: 1.0ms preprocess, 36.5ms inference, 12.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 bus, 3 trucks, 36.2ms\n",
      "Speed: 1.2ms preprocess, 36.2ms inference, 9.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 bus, 2 trucks, 36.7ms\n",
      "Speed: 1.6ms preprocess, 36.7ms inference, 9.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 cars, 1 bus, 3 trucks, 36.1ms\n",
      "Speed: 1.1ms preprocess, 36.1ms inference, 8.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 bus, 3 trucks, 36.4ms\n",
      "Speed: 1.4ms preprocess, 36.4ms inference, 12.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 bus, 2 trucks, 36.5ms\n",
      "Speed: 1.7ms preprocess, 36.5ms inference, 10.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 bus, 2 trucks, 36.8ms\n",
      "Speed: 1.8ms preprocess, 36.8ms inference, 12.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 bus, 2 trucks, 36.2ms\n",
      "Speed: 2.1ms preprocess, 36.2ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 bus, 2 trucks, 36.4ms\n",
      "Speed: 2.2ms preprocess, 36.4ms inference, 14.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 bus, 2 trucks, 36.5ms\n",
      "Speed: 1.4ms preprocess, 36.5ms inference, 14.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 bus, 2 trucks, 36.2ms\n",
      "Speed: 1.9ms preprocess, 36.2ms inference, 15.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 bus, 2 trucks, 36.4ms\n",
      "Speed: 1.2ms preprocess, 36.4ms inference, 11.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 bus, 2 trucks, 36.1ms\n",
      "Speed: 1.1ms preprocess, 36.1ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 bus, 2 trucks, 36.4ms\n",
      "Speed: 1.1ms preprocess, 36.4ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 bus, 2 trucks, 46.5ms\n",
      "Speed: 1.3ms preprocess, 46.5ms inference, 11.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 bus, 2 trucks, 120.9ms\n",
      "Speed: 1.3ms preprocess, 120.9ms inference, 9.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 bus, 2 trucks, 36.6ms\n",
      "Speed: 1.7ms preprocess, 36.6ms inference, 9.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 bus, 2 trucks, 36.0ms\n",
      "Speed: 1.4ms preprocess, 36.0ms inference, 9.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 bus, 2 trucks, 124.3ms\n",
      "Speed: 1.9ms preprocess, 124.3ms inference, 11.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 bus, 2 trucks, 197.3ms\n",
      "Speed: 1.7ms preprocess, 197.3ms inference, 9.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 bus, 2 trucks, 36.1ms\n",
      "Speed: 1.3ms preprocess, 36.1ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 1 bus, 2 trucks, 38.3ms\n",
      "Speed: 1.5ms preprocess, 38.3ms inference, 13.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 bus, 2 trucks, 142.8ms\n",
      "Speed: 2.8ms preprocess, 142.8ms inference, 20.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 bus, 2 trucks, 277.2ms\n",
      "Speed: 2.7ms preprocess, 277.2ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 bus, 2 trucks, 36.3ms\n",
      "Speed: 1.3ms preprocess, 36.3ms inference, 14.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 bus, 2 trucks, 36.2ms\n",
      "Speed: 2.2ms preprocess, 36.2ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 2 trucks, 36.4ms\n",
      "Speed: 2.5ms preprocess, 36.4ms inference, 18.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 2 trucks, 36.0ms\n",
      "Speed: 1.2ms preprocess, 36.0ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 2 trucks, 36.3ms\n",
      "Speed: 1.9ms preprocess, 36.3ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 2 trucks, 36.1ms\n",
      "Speed: 1.3ms preprocess, 36.1ms inference, 12.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 cars, 2 trucks, 36.2ms\n",
      "Speed: 2.6ms preprocess, 36.2ms inference, 13.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 2 trucks, 36.1ms\n",
      "Speed: 2.1ms preprocess, 36.1ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 bus, 1 truck, 36.2ms\n",
      "Speed: 1.1ms preprocess, 36.2ms inference, 8.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 2 trucks, 36.1ms\n",
      "Speed: 1.4ms preprocess, 36.1ms inference, 8.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 1 bus, 2 trucks, 52.7ms\n",
      "Speed: 1.4ms preprocess, 52.7ms inference, 14.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 bus, 2 trucks, 121.9ms\n",
      "Speed: 1.7ms preprocess, 121.9ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 bus, 2 trucks, 150.9ms\n",
      "Speed: 2.0ms preprocess, 150.9ms inference, 14.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 bus, 2 trucks, 36.2ms\n",
      "Speed: 1.8ms preprocess, 36.2ms inference, 11.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 bus, 2 trucks, 36.5ms\n",
      "Speed: 2.0ms preprocess, 36.5ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 bus, 2 trucks, 124.4ms\n",
      "Speed: 1.7ms preprocess, 124.4ms inference, 15.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 1 bus, 3 trucks, 260.8ms\n",
      "Speed: 2.3ms preprocess, 260.8ms inference, 16.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 bus, 2 trucks, 56.4ms\n",
      "Speed: 2.5ms preprocess, 56.4ms inference, 14.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 bus, 2 trucks, 36.2ms\n",
      "Speed: 2.6ms preprocess, 36.2ms inference, 8.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 bus, 3 trucks, 66.4ms\n",
      "Speed: 1.6ms preprocess, 66.4ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 2 trucks, 113.2ms\n",
      "Speed: 1.4ms preprocess, 113.2ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 2 trucks, 36.1ms\n",
      "Speed: 1.3ms preprocess, 36.1ms inference, 9.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 2 trucks, 36.5ms\n",
      "Speed: 2.3ms preprocess, 36.5ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 2 trucks, 136.6ms\n",
      "Speed: 2.2ms preprocess, 136.6ms inference, 14.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 2 trucks, 165.2ms\n",
      "Speed: 2.6ms preprocess, 165.2ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 2 trucks, 36.0ms\n",
      "Speed: 1.3ms preprocess, 36.0ms inference, 12.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 2 trucks, 36.1ms\n",
      "Speed: 1.2ms preprocess, 36.1ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 2 trucks, 114.2ms\n",
      "Speed: 1.9ms preprocess, 114.2ms inference, 14.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 cars, 2 trucks, 199.6ms\n",
      "Speed: 2.0ms preprocess, 199.6ms inference, 10.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 bus, 2 trucks, 36.1ms\n",
      "Speed: 1.4ms preprocess, 36.1ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 bus, 2 trucks, 36.1ms\n",
      "Speed: 1.3ms preprocess, 36.1ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 cars, 1 bus, 2 trucks, 117.6ms\n",
      "Speed: 2.5ms preprocess, 117.6ms inference, 10.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 2 trucks, 188.4ms\n",
      "Speed: 1.7ms preprocess, 188.4ms inference, 15.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "\n",
    "model = YOLO('yolo11m.pt').to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "cap = cv2.VideoCapture('Sample.mp4')\n",
    "class_counts = defaultdict(int)\n",
    "crossed_ids = set()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (640, 360))  # reduce resolution for speed\n",
    "    height, width, _ = frame.shape\n",
    "    line_y_red = int(height * 0.6)  # draw line at 75% of frame height\n",
    "\n",
    "    results = model.track(frame, persist=True, classes=[1,2,3,5,6,7])\n",
    "    if results and results[0].boxes.data is not None:\n",
    "        boxes = results[0].boxes.xyxy.cpu()\n",
    "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "        class_indices = results[0].boxes.cls.int().cpu().tolist()\n",
    "\n",
    "        # Red line\n",
    "        cv2.line(frame, (int(width * 0.2), line_y_red), (int(width * 0.85), line_y_red), (0, 0, 255), 3)\n",
    "\n",
    "        for box, tid, cls_idx in zip(boxes, track_ids, class_indices):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            cx, cy = (x1 + x2)//2, (y1 + y2)//2\n",
    "            class_name = model.names[cls_idx]\n",
    "\n",
    "            cv2.circle(frame, (cx, cy), 3, (0, 0, 255), -1)\n",
    "            cv2.putText(frame, f\"{class_name}\", (x1, y1-10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "            cv2.rectangle(frame, (x1,y1), (x2,y2), (0,255,0), 2)\n",
    "\n",
    "            if cy > line_y_red and tid not in crossed_ids:\n",
    "                crossed_ids.add(tid)\n",
    "                class_counts[class_name] += 1\n",
    "\n",
    "        y = 30\n",
    "        for cls, count in class_counts.items():\n",
    "            cv2.putText(frame, f\"{cls}: {count}\", (30, y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2)\n",
    "            y += 30\n",
    "\n",
    "    cv2.imshow(\"YOLO Tracking\", frame)\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89d5d98-c32f-4372-b355-4243f74aa6c7",
   "metadata": {},
   "source": [
    "### faster execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9f2774-23f9-4862-b894-cbadd5de4d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (yoloenv)",
   "language": "python",
   "name": "yoloenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
